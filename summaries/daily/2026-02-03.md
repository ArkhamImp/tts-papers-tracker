# TTS 论文日报
**日期**: 2026-02-03
**生成时间**: 2026-02-05 10:30

## 概览
- **论文数**: 1
- **主题分布**:
  - `expressive`: 1
  - `synthesis`: 1

## 重点论文（分析摘要）
- **CoCoEmo: Composable and Controllable Human-Like Emotional TTS via Activation Steering**
  - 作者: Siyi Wang et.al.
  - arXiv: [2602.03420](https://arxiv.org/abs/2602.03420)
  - 标签: expressive, synthesis
  - 摘要: Emotional expression in human speech is nuanced and compositional, often involving multiple, sometimes conflicting, affective cues that may diverge from linguistic content. In contrast, most expressive text-to-speech systems enforce a single utterance-level emotion, collapsing affective diversity and suppressing mixed or text-emotion-misaligned expression. While activation steering via latent direction vectors offers a promising solution, it remains unclear whether emotion representations are linearly steerable in TTS, where steering should be applied within hybrid TTS architectures, and how such complex emotion behaviors should be evaluated. This paper presents the first systematic analysis of activation steering for emotional control in hybrid TTS models, introducing a quantitative, controllable steering framework, and multi-rater evaluation protocols that enable composable mixed-emotion synthesis and reliable text-emotion mismatch synthesis. Our results demonstrate, for the first time, that emotional prosody and expressive variability are primarily synthesized by the TTS language module instead of the flow-matching module, and also provide a lightweight steering approach for generating natural, human-like emotional speech.

## 完整列表（带分析摘要）
- **CoCoEmo: Composable and Controllable Human-Like Emotional TTS via Activation Steering**
  - 作者: Siyi Wang et.al.
  - arXiv: [2602.03420](https://arxiv.org/abs/2602.03420)
  - 摘要: Emotional expression in human speech is nuanced and compositional, often involving multiple, sometimes conflicting, affective cues that may diverge from linguistic content. In contrast, most expressive text-to-speech systems enforce a single utterance-level emotion, collapsing affective diversity and suppressing mixed or text-emotion-misaligned expression. While activation steering via latent direction vectors offers a promising solution, it remains unclear whether emotion representations are linearly steerable in TTS, where steering should be applied within hybrid TTS architectures, and how such complex emotion behaviors should be evaluated. This paper presents the first systematic analysis of activation steering for emotional control in hybrid TTS models, introducing a quantitative, controllable steering framework, and multi-rater evaluation protocols that enable composable mixed-emotion synthesis and reliable text-emotion mismatch synthesis. Our results demonstrate, for the first time, that emotional prosody and expressive variability are primarily synthesized by the TTS language module instead of the flow-matching module, and also provide a lightweight steering approach for generating natural, human-like emotional speech.
