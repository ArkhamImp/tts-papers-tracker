# TTS 论文日报
**日期**: 2026-02-02
**生成时间**: 2026-02-04 09:52

## 概览
- **论文数**: 1
- **主题分布**:
  - `expressive`: 1
  - `synthesis`: 1

## 重点论文（分析摘要）
- **LipSody: Lip-to-Speech Synthesis with Enhanced Prosody Consistency**
  - 作者: Jaejun Lee et.al.
  - arXiv: [2602.01908](https://arxiv.org/abs/2602.01908)
  - 标签: expressive, synthesis
  - TLDR: LipSody improves lip-to-speech synthesis by explicitly modeling prosody consistency using speaker identity, linguistic content, and emotional context from facial video.
  - 核心贡献: Introduces a novel visual-only prosody estimation method and integrates it into a diffusion-based lip-to-speech framework to enhance prosody consistency while maintaining intelligibility.
  - 方法: Builds on diffusion-based LipVoicer architecture, adds explicit prosody modeling using speaker identity, linguistic content, and emotional context from face video; uses conformer-based lip-reading and HiFi-GAN vocoder; trained with DDPM and CFG guidance.
  - 关键发现: Significantly improves prosody-related metrics (pitch deviation, energy consistency, speaker similarity) over LipVoicer while maintaining high intelligibility (WER); subjective tests show better naturalness and preference.
  - 局限性: Focuses on prosody consistency but may still face challenges in extreme emotional or speaker variability; evaluation limited to LRS3 dataset; some results omitted due to space constraints.
  - 评估: medium (评分: 7/10)

## 完整列表（带分析摘要）
- **LipSody: Lip-to-Speech Synthesis with Enhanced Prosody Consistency**
  - 作者: Jaejun Lee et.al.
  - arXiv: [2602.01908](https://arxiv.org/abs/2602.01908)
  - TLDR: LipSody improves lip-to-speech synthesis by explicitly modeling prosody consistency using speaker identity, linguistic content, and emotional context from facial video.
  - 核心贡献: Introduces a novel visual-only prosody estimation method and integrates it into a diffusion-based lip-to-speech framework to enhance prosody consistency while maintaining intelligibility.
  - 关键发现: Significantly improves prosody-related metrics (pitch deviation, energy consistency, speaker similarity) over LipVoicer while maintaining high intelligibility (WER); subjective tests show better naturalness and preference.
