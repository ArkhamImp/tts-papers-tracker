# TTS Papers - 2026-01-29

Total: 2

## Speech Quality-Based Localization of Low-Quality Speech and Text-to-Speech Synthesis Artefacts
- **Authors**: Michael Kuhlmann et.al.
- **arXiv**: [2601.21886](https://arxiv.org/abs/2601.21886)
- **Tags**: synthesis
- **Abstract**: A large number of works view the automatic assessment of speech from an utterance- or system-level perspective. While such approaches are good in judging overall quality, they cannot adequately explain why a certain score was assigned to an utterance. frame-level scores can provide better interpretability, but models predicting them are harder to tune and regularize since no strong targets are available during training. In this work, we show that utterance-level speech quality predictors can be regularized with a segment-based consistency constraint which notably reduces frame-level stochasticity. We then demonstrate two applications involving frame-level scores: The partial spoof scenario and the detection of synthesis artefacts in two state-of-the-art text-to-speech systems. For the latter, we perform listening tests and confirm that listeners rate segments to be of poor quality more often in the set defined by low frame-level scores than in a random control set.

## Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems
- **Authors**: Haoyuan Yu et.al.
- **arXiv**: [2601.20230](https://arxiv.org/abs/2601.20230)
- **Tags**: other
- **Abstract**: Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.

