# TTS Papers - 2023-03-07

Total: 2

## Do Prosody Transfer Models Transfer Prosody?
- **Authors**: Atli Thor Sigurgeirsson et.al.
- **arXiv**: [2303.04289](https://arxiv.org/abs/2303.04289)
- **Tags**: expressive
- **Abstract**: Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction. With the diffusion model as the most popular generative model, numerous works have attempted two active tasks: text to speech and speech enhancement. This work conducts a survey on audio diffusion model, which is complementary to existing surveys that either lack the recent progress of diffusion-based speech synthesis or highlight an overall picture of applying diffusion model in multiple fields. Specifically, this work first briefly introduces the background of audio and diffusion model. As for the text-to-speech task, we divide the methods into three categories based on the stage where diffusion model is adopted: acoustic model, vocoder and end-to-end framework. Moreover, we categorize various speech enhancement tasks by either certain signals are removed or added into the input speech. Comparisons of experimental results and discussions are also covered in this survey.

## Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling
- **Authors**: Ziqiang Zhang et.al.
- **arXiv**: [2303.03926](https://arxiv.org/abs/2303.03926)
- **Tags**: multilingual, codec
- **Abstract**: State-of-the-art Text-To-Speech (TTS) models are capable of producing high-quality speech. The generated speech, however, is usually neutral in emotional expression, whereas very often one would want fine-grained emotional control of words or phonemes. Although still challenging, the first TTS models have been recently proposed that are able to control voice by manually assigning emotion intensity. Unfortunately, due to the neglect of intra-class distance, the intensity differences are often unrecognizable. In this paper, we propose a fine-grained controllable emotional TTS, that considers both inter- and intra-class distances and be able to synthesize speech with recognizable intensity difference. Our subjective and objective experiments demonstrate that our model exceeds two state-of-the-art controllable TTS models for controllability, emotion expressiveness and naturalness.

