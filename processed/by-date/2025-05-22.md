# TTS Papers - 2025-05-22

Total: 3

## Benchmarking Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2
- **Authors**: Zackary Rackauckas et.al.
- **arXiv**: [2505.17320](https://arxiv.org/abs/2505.17320)
- **Tags**: expressive, synthesis

## MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing
- **Authors**: Junjie Zheng et.al.
- **arXiv**: [2505.16279](https://arxiv.org/abs/2505.16279)
- **Tags**: other
- **Abstract**: We present a model for predicting articulatory features from surface electromyography (EMG) signals during speech production. The proposed model integrates convolutional layers and a Transformer block, followed by separate predictors for articulatory features. Our approach achieves a high prediction correlation of approximately 0.9 for most articulatory features. Furthermore, we demonstrate that these predicted articulatory features can be decoded into intelligible speech waveforms. To our knowledge, this is the first method to decode speech waveforms from surface EMG via articulatory features, offering a novel approach to EMG-based speech synthesis. Additionally, we analyze the relationship between EMG electrode placement and articulatory feature predictability, providing knowledge-driven insights for optimizing EMG electrode configurations. The source code and decoded speech samples are publicly available.

## Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising
- **Authors**: Ye-Xin Lu et.al.
- **arXiv**: [2505.13830](https://arxiv.org/abs/2505.13830)
- **Tags**: zero-shot, codec, llm-based, synthesis
- **Abstract**: Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.

