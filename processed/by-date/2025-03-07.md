# TTS Papers - 2025-03-07

Total: 1

## DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility
- **Authors**: Yifan Liu et.al.
- **arXiv**: [2503.05223](https://arxiv.org/abs/2503.05223)
- **Tags**: synthesis
- **Abstract**: This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.

