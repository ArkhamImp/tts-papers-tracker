# TTS Papers - 2024-12-28

Total: 1

## Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody Prompting
- **Authors**: Wooseok Han et.al.
- **arXiv**: [2412.20155](https://arxiv.org/abs/2412.20155)
- **Tags**: expressive, synthesis
- **Abstract**: Although text-based large language models exhibit human-level writing ability and remarkable intelligence, speech language models (SLMs) still struggle to generate semantically coherent outputs. There are several potential reasons for this performance degradation: (A) speech tokens mainly provide phonetic information rather than semantic information, (B) the length of speech sequences is much longer than that of text sequences, and (C) paralinguistic information, such as prosody, introduces additional complexity and variability. In this paper, we explore the influence of three key factors separately by transiting the modality from text to speech in an evolving manner. Our findings reveal that the impact of the three factors varies. Factor A has a relatively minor impact, factor B influences syntactical and semantic modeling more obviously, and factor C exerts the most significant impact, particularly in the basic lexical modeling. Based on these findings, we provide insights into the unique challenges of training SLMs and highlight pathways to develop more effective end-to-end SLMs.

