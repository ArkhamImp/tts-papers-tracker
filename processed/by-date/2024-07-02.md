# TTS Papers - 2024-07-02

Total: 3

## Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization
- **Authors**: Yuchen Hu et.al.
- **arXiv**: [2407.02243](https://arxiv.org/abs/2407.02243)
- **Tags**: zero-shot, synthesis
- **Abstract**: Different languages have distinct phonetic systems and vary in their prosodic features making it challenging to develop a Text-to-Speech (TTS) model that can effectively synthesise speech in multilingual settings. Furthermore, TTS architecture needs to be both efficient enough to capture nuances in multiple languages and efficient enough to be practical for deployment. The standard approach is to build transformer based model such as SpeechT5 and train it on large multilingual dataset. As the size of these models grow the conventional fine-tuning for adapting these model becomes impractical due to heavy computational cost. In this paper, we proposes to integrate parameter-efficient transfer learning (PETL) methods such as adapters and hypernetwork with TTS architecture for multilingual speech synthesis. Notably, in our experiments PETL methods able to achieve comparable or even better performance compared to full fine-tuning with only $\sim$2.5\% tunable parameters.The code and samples are available at: https://anonymous.4open.science/r/multilingualTTS-BA4C.

## TTSlow: Slow Down Text-to-Speech with Efficiency Robustness Evaluations
- **Authors**: Xiaoxue Gao et.al.
- **arXiv**: [2407.01927](https://arxiv.org/abs/2407.01927)
- **Tags**: synthesis
- **Abstract**: People change their tones of voice, often accompanied by nonverbal vocalizations (NVs) such as laughter and cries, to convey rich emotions. However, most text-to-speech (TTS) systems lack the capability to generate speech with rich emotions, including NVs. This paper introduces EmoCtrl-TTS, an emotion-controllable zero-shot TTS that can generate highly emotional speech with NVs for any speaker. EmoCtrl-TTS leverages arousal and valence values, as well as laughter embeddings, to condition the flow-matching-based zero-shot TTS. To achieve high-quality emotional speech generation, EmoCtrl-TTS is trained using more than 27,000 hours of expressive data curated based on pseudo-labeling. Comprehensive evaluations demonstrate that EmoCtrl-TTS excels in mimicking the emotions of audio prompts in speech-to-speech translation scenarios. We also show that EmoCtrl-TTS can capture emotion changes, express strong emotions, and generate various NVs in zero-shot TTS. See https://aka.ms/emoctrl-tts for demo samples.

## Open-Source Conversational AI with SpeechBrain 1.0
- **Authors**: Mirco Ravanelli et.al.
- **arXiv**: [2407.00463](https://arxiv.org/abs/2407.00463)
- **Tags**: other

