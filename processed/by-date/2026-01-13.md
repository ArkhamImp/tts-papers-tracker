# TTS Papers - 2026-01-13

Total: 1

## Decoding Order Matters in Autoregressive Speech Synthesis
- **Authors**: Minghui Zhao et.al.
- **arXiv**: [2601.08450](https://arxiv.org/abs/2601.08450)
- **Tags**: synthesis
- **Abstract**: Autoregressive speech synthesis often adopts a left-to-right order, yet generation order is a modelling choice. We investigate decoding order through masked diffusion framework, which progressively unmasks positions and allows arbitrary decoding orders during training and inference. By interpolating between identity and random permutations, we show that randomness in decoding order affects speech quality. We further compare fixed strategies, such as \texttt{l2r} and \texttt{r2l} with adaptive ones, such as Top-$K$, finding that fixed-order decoding, including the dominating left-to-right approach, is suboptimal, while adaptive decoding yields better performance. Finally, since masked diffusion requires discrete inputs, we quantise acoustic representations and find that even 1-bit quantisation can support reasonably high-quality speech.

