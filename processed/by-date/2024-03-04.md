# TTS Papers - 2024-03-04

Total: 2

## Brilla AI: AI Contestant for the National Science and Maths Quiz
- **Authors**: George Boateng et.al.
- **arXiv**: [2403.01699](https://arxiv.org/abs/2403.01699)
- **Tags**: other
- **Abstract**: Collecting high-quality studio recordings of audio is challenging, which limits the language coverage of text-to-speech (TTS) systems. This paper proposes a framework for scaling a multilingual TTS model to 100+ languages using found data without supervision. The proposed framework combines speech-text encoder pretraining with unsupervised training using untranscribed speech and unspoken text data sources, thereby leveraging massively multilingual joint speech and text representation learning. Without any transcribed speech in a new language, this TTS model can generate intelligible speech in &gt;30 unseen languages (CER difference of &lt;10% to ground truth). With just 15 minutes of transcribed, found data, we can reduce the intelligibility difference to 1% or less from the ground-truth, and achieve naturalness scores that match the ground-truth in several languages.

## Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like
- **Authors**: Naoyuki Kanda et.al.
- **arXiv**: [2402.07383](https://arxiv.org/abs/2402.07383)
- **Tags**: zero-shot, synthesis
- **Abstract**: Data availability is crucial for advancing artificial intelligence applications, including voice-based technologies. As content creation, particularly in social media, experiences increasing demand, translation and text-to-speech (TTS) technologies have become essential tools. Notably, the performance of these TTS technologies is highly dependent on the quality of the training data, emphasizing the mutual dependence of data availability and technological progress. This paper introduces an end-to-end tool to generate high-quality datasets for text-to-speech (TTS) models to address this critical need for high-quality data. The contributions of this work are manifold and include: the integration of language-specific phoneme distribution into sample selection, automation of the recording process, automated and human-in-the-loop quality assurance of recordings, and processing of recordings to meet specified formats. The proposed application aims to streamline the dataset creation process for TTS models through these features, thereby facilitating advancements in voice-based technologies.

