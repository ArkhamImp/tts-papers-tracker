# TTS Papers - 2024-12-25

Total: 1

## Advancing NAM-to-Speech Conversion with Novel Methods and the MultiNAM Dataset
- **Authors**: Neil Shah et.al.
- **arXiv**: [2412.18839](https://arxiv.org/abs/2412.18839)
- **Tags**: other
- **Abstract**: While Large Language Models (LLMs) have demonstrated impressive natural language understanding capabilities across various text-based tasks, understanding humor has remained a persistent challenge. Humor is frequently multimodal, relying on phonetic ambiguity, rhythm and timing to convey meaning. In this study, we explore a simple multimodal prompting approach to humor understanding and explanation. We present an LLM with both the text and the spoken form of a joke, generated using an off-the-shelf text-to-speech (TTS) system. Using multimodal cues improves the explanations of humor compared to textual prompts across all tested datasets.

