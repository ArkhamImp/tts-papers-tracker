# TTS Papers - 2023-06-16

Total: 2

## Low-Resource Text-to-Speech Using Specific Data and Noise Augmentation
- **Authors**: Kishor Kayyar Lakshminarayana et.al.
- **arXiv**: [2306.10152](https://arxiv.org/abs/2306.10152)
- **Tags**: synthesis
- **Abstract**: Regressive Text-to-Speech (TTS) system utilizes attention mechanism to generate alignment between text and acoustic feature sequence. Alignment determines synthesis robustness (e.g, the occurence of skipping, repeating, and collapse) and rhythm via duration control. However, current attention algorithms used in speech synthesis cannot control rhythm using external duration information to generate natural speech while ensuring robustness. In this study, we propose Rhythm-controllable Attention (RC-Attention) based on Tracotron2, which improves robustness and naturalness simultaneously. Proposed attention adopts a trainable scalar learned from four kinds of information to achieve rhythm control, which makes rhythm control more robust and natural, even when synthesized sentences are extremely longer than training corpus. We use word errors counting and AB preference test to measure robustness of proposed method and naturalness of synthesized speech, respectively. Results shows that RC-Attention has the lowest word error rate of nearly 0.6%, compared with 11.8% for baseline system. Moreover, nearly 60% subjects prefer to the speech synthesized with RC-Attention to that with Forward Attention, because the former has more natural rhythm.

## CML-TTS A Multilingual Dataset for Speech Synthesis in Low-Resource Languages
- **Authors**: Frederico S. Oliveira et.al.
- **arXiv**: [2306.10097](https://arxiv.org/abs/2306.10097)
- **Tags**: multilingual, synthesis
- **Abstract**: In this work, we studied the synthesis of Swiss German speech using different Text-to-Speech (TTS) models. We evaluated the TTS models on three corpora, and we found, that VITS models performed best, hence, using them for further testing. We also introduce a new method to evaluate TTS models by letting the discriminator of a trained vocoder GAN model predict whether a given waveform is human or synthesized. In summary, our best model delivers speech synthesis for different Swiss German dialects with previously unachieved quality.

